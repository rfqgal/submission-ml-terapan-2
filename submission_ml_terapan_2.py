# -*- coding: utf-8 -*-
"""Submission ML Terapan 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14wIj6Gf80K-ySBkHC7mMQ3YwXBimaVm4

# Sistem Rekomendasi Produk Skincare

## **Import Library**

Mengimpor beberapa pustaka (library) Python yang dibutuhkan.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
from google.colab import files
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.compose import ColumnTransformer
from sklearn.utils import resample
from tensorflow import keras
from keras import layers, regularizers
from tqdm import tqdm

"""## **Data Loading**

Mendownload dataset dari sumbernya, lalu memuatnya ke dalam notebook. Kemudian memahami struktur dataset dan memastikannya telah termuat dengan benar.
"""

!wget https://www.kaggle.com/api/v1/datasets/download/nadyinky/sephora-products-and-skincare-reviews

!unzip sephora-products-and-skincare-reviews

df_product = pd.read_csv('product_info.csv')
df_product.head()

df_review_250 = pd.read_csv('reviews_0-250.csv')
df_review_500 = pd.read_csv('reviews_250-500.csv')

print(df_review_250.info(), df_review_500.info())

"""Dikarenakan kedua dataset review memiliki struktur data yang sama, maka bisa digabung menjadi satu dataset."""

df_review = pd.concat([df_review_250, df_review_500], ignore_index=True)
df_review

"""Kolom `Unnamed: 0` dihapus karena hanya berisi ID dari masing-masing berkas CSV dataset. Hal ini akan mempermudah proses analisis dataset di tahap selanjutnya."""

df_review = df_review.drop(columns=['Unnamed: 0'])
df_review.head()

"""## **Exploratory Data Analysis**

Exploratory Data Analysis (EDA) dilakukan untuk memahami karakteristik dataset. EDA bertujuan untuk:

1. Memahami Struktur Data
  - Meninjau jumlah baris dan kolom dalam dataset.
  - Meninjau jenis data di setiap kolom (numerikal atau kategorikal).

2. Identifikasi Nilai yang Hilang dan Terduplikasi
3. Analisis Distribusi, Korelasi, dan Visualisasi Data
  - Analisis distribusi variabel numerik dengan statistik deskriptif dan visualisasi seperti histogram atau boxplot.
  - Periksa hubungan antara variabel menggunakan matriks korelasi atau scatter plot.

### **1. Memahami Struktur Data**
"""

df_product.info()

df_review.info()

df_product.shape

"""Data produk terdiri dari 8.494 baris dan 27 kolom."""

df_review.shape

"""Data review terdiri dari 808.855 baris dan 18 kolom.

### **2. Identifikasi Nilai yang Hilang dan Terduplikasi**
"""

df_product.isna().sum()

"""Ternyata banyak missing values yang ditemukan pada data produk. Sehingga saya akan fokus ke fitur yang relevan saja."""

df_product_relevant = df_product.copy()
df_product_relevant = df_product_relevant[['product_name','brand_name','rating','reviews']]

df_product_relevant.duplicated().sum()

"""Pada data produk juga ditemukan adanya 4 nilai yang duplikat."""

df_review.isna().sum()

"""Ternyata banyak missing values yang ditemukan pada data review. Sehingga saya akan fokus ke fitur yang relevan saja."""

df_review_relevant = df_review.copy()
df_review_relevant = df_review_relevant[['author_id','rating','is_recommended','skin_type','product_name','brand_name']]

df_review_relevant.duplicated().sum()

"""Pada data review juga ditemukan adanya 4.442 nilai yang duplikat."""

df_merged = pd.merge(df_review_relevant, df_product_relevant, on=['product_name', 'brand_name'], how='left', suffixes=('_reviews', '_products'))
df_merged.head()

df_merged.info()

df_merged.isna().sum()

df_merged.duplicated().sum()

"""Banyak duplikasi ditemukan setelah merge, ada kemungkinan banyak review yang diberikan untuk satu produk. Nilai duplikat tidak saya hapus karena adanya duplikasi ini menandakan realitas interaksi pengguna dengan produk.

### **3. Analisis Distribusi dan Korelasi**
"""

df_merged.info()

numeric_features = df_merged.select_dtypes(include=['int64', 'float64'])
categorical_features = df_merged.select_dtypes(include=['object'])

numeric_columns = numeric_features.columns
categorical_columns = categorical_features.columns

"""#### **Distribusi Fitur Numerik**"""

plt.figure(figsize=(12, 6))
for i, col in enumerate(numeric_columns, 1):
    plt.subplot(2, 3, i)
    sns.histplot(df_merged[col], bins=30, kde=True)
    plt.title(f'Distribusi {col}')
plt.tight_layout()

"""#### **Distribusi Jenis Kulit**"""

plt.figure(figsize=(18, 12))
plt.subplot(2, 2, i)
sns.histplot(df_merged['skin_type'], bins=30, kde=True)
plt.title(f'Distribusi Skin Type')
plt.xticks(rotation=15)
plt.tight_layout()

"""Terdapat 9 fitur untuk dilakukan analisis korelasinya:

1. **product_name**: nama produk     
2. **brand_name**: nama brand     
3. **rating_products**: rata-rata rating produk berdasarkan user reviews
4. **reviews**: jumlah user reviews suatu produk       
5. **author_id**: identifier unik dari penulis review       
6. **rating_reviews**: rating yang diberikan penulis review terhadap produk
7. **is_recommended**: indikator apakah produk direkomendasikan oleh penulis review
8. **skin_type**: jenis kulit yang dimiliki oleh penulis review

#### **Univariate Analysis**
"""

# Fitur author_id
feature = categorical_columns[0]
count = df_merged[feature].value_counts()
percent = 100 * df_merged[feature].value_counts(normalize=True)
count_percent = pd.DataFrame({'Jumlah': count, 'Persentase': percent.round(1)})

print(count_percent)
print('Jumlah Author:', df_merged[feature].nunique())

# Fitur skin_type
feature = categorical_columns[1]
count = df_merged[feature].value_counts()
percent = 100 * df_merged[feature].value_counts(normalize=True)
count_percent = pd.DataFrame({'Jumlah': count, 'Persentase': percent.round(1)})

print(count_percent)
print('Jumlah Jenis Kulit:', df_merged[feature].nunique())

# Fitur product_name
feature = categorical_columns[2]
count = df_merged[feature].value_counts()
percent = 100 * df_merged[feature].value_counts(normalize=True)
count_percent = pd.DataFrame({'Jumlah': count, 'Persentase': percent.round(1)})

print(count_percent)
print('Jumlah Produk:', df_merged[feature].nunique())

# Fitur brand_name
feature = categorical_columns[3]
count = df_merged[feature].value_counts()
percent = 100 * df_merged[feature].value_counts(normalize=True)
count_percent = pd.DataFrame({'Jumlah': count, 'Persentase': percent.round(1)})

print(count_percent)
print('Jumlah Brand:', df_merged[feature].nunique())

"""#### **Multivariate Analysis**"""

# Hubungan antar fitur numerik dengan pairplot
sns.pairplot(df_merged, diag_kind='kde')

# Korelasi antar fitur numerik
correlation_matrix = numeric_features.corr().round(2)

plt.figure(figsize=(10, 8))
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Dari heatmap korelasi diatas, didapati insight bahwa semakin tinggi rating maka semakin besar kemungkinan user merekomendasikan produk.

## **Data Preparation**

Tahap ini memastikan kualitas data telah baik sebelum digunakan dalam model machine learning. Pada tahap ini proses transformasi data dilakukan. Berikut hal-hal yang akan dilakukan:
 1. Menangani Missing Values
 2. Mengubah Tipe Data yang Belum Sesuai
 3. Identifikasi dan Menangani Outliers
 4. Undersampling
 5. Data Splitting
 5. Feature Encoding dan Scaling

### **1. Menangani Missing Values**

Penanganan pada kasus ini yaitu dengan menghapus baris yang mengandung nilai yang hilang.
"""

df_merged = df_merged.dropna()

df_merged.isna().sum()

"""### **2. Mengubah Tipe Data yang Belum Sesuai**"""

df_merged['is_recommended'] = df_merged['is_recommended'].astype(int)
df_merged['reviews'] = df_merged['reviews'].astype(int)

df_merged.info()

"""### **3. Identifikasi dan Menangani Outliers**"""

numeric_features = df_merged.select_dtypes(include=['number'])

def detect_outliers(data):
    Q1 = data[data.columns].quantile(0.25)
    Q3 = data[data.columns].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outlier_mask = (data[data.columns] < lower_bound) | (data[data.columns] > upper_bound)
    outliers = data[outlier_mask.any(axis=1)].index
    return outliers

detect_outliers(numeric_features)

plt.figure(figsize=(16, 8))
for i, col in enumerate(numeric_features.columns, 1):
    plt.subplot(2, 3, i)
    sns.boxplot(data=numeric_features[col])
    plt.title(f'Boxplot {col}')
    plt.tight_layout()

"""Ternyata terdeteksi ada banyak outliers, namun saya menganggap nilai ekstrem dari kolom-kolom numerik tersebut merupakan outliers dalam konteks bisnis. **Statistical Outliers tidak sama dengan Business Outliers**.

Contohnya pada kolom `rating_reviews` di mana banyak user yang memberi rating di angka 4-5, lalu ada juga user yang memberi rating 1 atau 2. Nilai-nilai ini mungkin bisa dianggap outliers secara statistik, namun sebenarnya masih masuk akal untuk dianggap sebagai sebuah nilai. Sehingga, pada kasus ini outliers tidak di-drop ataupun dilakukan manipulasi.

### **4. Undersampling**

Pada tahap EDA telah diketahui bahwa untuk fitur **skin_type** terdapat ketidakseimbangan distribusi, sehingga perlu dilakukan undersampling agar tidak terjadi bias pada kelas mayoritas.
"""

df_merged['skin_type'].value_counts()

min_count = df_merged['skin_type'].value_counts().min()
min_count

u_combination_type = resample(df_merged[df_merged['skin_type'] == 'combination'],
                              replace=False,
                              n_samples=min_count,
                              random_state=42)

u_dry_type = resample(df_merged[df_merged['skin_type'] == 'dry'],
                      replace=False,
                      n_samples=min_count,
                      random_state=42)

normal_type = df_merged[df_merged['skin_type'] == 'normal']

oily_type = df_merged[df_merged['skin_type'] == 'oily']

df_undersampled = pd.concat([u_combination_type, u_dry_type, normal_type, oily_type])

df_undersampled['skin_type'].value_counts()

"""### **5. Data Splitting**"""

ds_train, ds_test = train_test_split(df_undersampled, test_size=0.2, random_state=42)

print(ds_train.shape, ds_test.shape)

print("Distribusi kelas di Train:")
print(ds_train['skin_type'].value_counts())

print("\nDistribusi kelas di Test:")
print(ds_test['skin_type'].value_counts())

"""### **6. Feature Encoding dan Scaling**"""

numeric_features = df_undersampled.select_dtypes(include=['number'])

print(numeric_features.columns)

preprocessor = ColumnTransformer(transformers=[
    ('num', Pipeline([
        ('scaler', StandardScaler())
    ]), numeric_features.columns),
    ('cat', Pipeline([
        ('encoder', OneHotEncoder(handle_unknown='ignore'))
    ]), ['skin_type'])
])

ds_train_transformed = preprocessor.fit_transform(ds_train)
ds_test_transformed = preprocessor.transform(ds_test)

df_train_transformed = pd.DataFrame(ds_train_transformed, columns=preprocessor.get_feature_names_out())
df_test_transformed = pd.DataFrame(ds_test_transformed, columns=preprocessor.get_feature_names_out())

df_test_transformed.head()

"""## **Model Development**

Setelah data sudah dipastikan bersih, maka dilanjut dengan mengembangkan model sistem rekomendasi dengan pendekatan:

**Content Based Filtering** yang berdasarkan pada `skin_type`.

### **Mendapatkan Vektor Representatif**
"""

skin_type_labels = ds_train['skin_type'].unique()
skin_type_encoded = []

for skin in skin_type_labels:
    skin_data_original = ds_train.reset_index()
    indices_for_skin = skin_data_original[skin_data_original['skin_type'] == skin].index
    skin_data_transformed = df_train_transformed.iloc[indices_for_skin]
    skin_profile_vector = skin_data_transformed.mean()
    skin_type_encoded.append(skin_profile_vector)

skin_type_encoded = np.array(skin_type_encoded)

"""### **Similarity Measure**"""

similarity_matrix = cosine_similarity(df_train_transformed, skin_type_encoded)

"""### **Mendapatkan Rekomendasi**

Menampilkan Top 5 Produk untuk Rekomendasi
"""

target_skin = 'oily'
target_index = list(skin_type_labels).index(target_skin)

df_train_transformed['similarity'] = similarity_matrix[:, target_index]
df_train_transformed = df_train_transformed.reset_index(drop=True)

df_recommendations = pd.merge(ds_train[['product_name', 'brand_name']], df_train_transformed, left_index=True, right_index=True)
df_recommendations['target_skin_type'] = target_skin

recommendations = df_recommendations.sort_values(by='similarity', ascending=False).drop_duplicates('product_name').reset_index(drop=True).head(5)
print(recommendations[['product_name', 'brand_name', 'similarity','target_skin_type']])

"""## **Evaluation**

Model yang sudah dikembangkan dievaluasi performanya mengenai rekomendasi yang dikeluarkan. Metrik evaluasi yang digunakan pada pendekatan Content Based Filtering ini adalah `precision@K` dan `recall@K`.
1. `precision@K`

  Mengukur berapa banyak dari K item teratas yang benar-benar relevan, sesuai dengan data ground truth (misal: `is_recommended=1`).

2. `recall@K`

  Mengukur seberapa banyak dari produk relevan yang berhasil direkomendasikan.
"""

df_combined_test = pd.concat([ds_test[['product_name', 'skin_type', 'is_recommended']].reset_index(drop=True),
                              df_test_transformed.reset_index(drop=True)], axis=1)

df_combined_test.head()

def precision_at_k_content(recommendations, ds_test, target_skin=None, k=5):
    recommended_products = recommendations['product_name'].head(k).values
    actual_recommended = ds_test[
        (ds_test['skin_type'] == target_skin) &
        (ds_test['is_recommended'] == 1)
    ]['product_name'].unique()
    relevant = set(recommended_products) & set(actual_recommended)
    return len(relevant) / k

precision = precision_at_k_content(recommendations, df_combined_test, target_skin)

print(f"Precision@5: {precision:.2f}")

def recall_at_k_content(recommendations, ds_test, target_skin=None, k=5):
    recommended_products = recommendations['product_name'].head(k).values
    actual_recommended = ds_test[
        (ds_test['skin_type'] == target_skin) &
        (ds_test['is_recommended'] == 1)
    ]['product_name'].unique()
    relevant = set(recommended_products) & set(actual_recommended)
    return len(relevant) / len(actual_recommended) if len(actual_recommended) > 0 else 0.0

recall = recall_at_k_content(recommendations, df_combined_test, target_skin)
print(f"Recall@5 (content-based): {recall:.2f}")

"""Nilai `recall@K` yang didapatkan ternyata rendah walaupun `precision@K` tinggi, itu artinya kasus ini memiliki kemungkinan bahwa banyak produk yang seharusnya direkomendasikan namun tidak termasuk ke dalam Top 5. Selain itu mungkin fitur kurang representatif, sehingga perlu penyesuaian kembali mengenai fitur yang digunakan ke dalam model misalnya menambahkan fitur seperti `ingredients`."""